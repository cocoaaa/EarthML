{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Disapearing Walker Lake\n",
    "\n",
    "While the loss of the Aral Sea in Kazakhstan and Lake Urmia in Iran have received a lot of attention over the last few decades, this trend is a global phenomena.  Reciently a number of __[papers](https://earthobservatory.nasa.gov/IOTD/view.php?id=91921)__ have been published including one focusing on the __[Decline of the world's saline lakes](https://www.nature.com/articles/ngeo3052)__.  Many of these lakes have lost the majority of their volume over the last century, including Walker Lake (Nevada, USA) which has lost 90 percent of its volume over the last 100 years.\n",
    "\n",
    "The following example is intended to replicate the typical processing required in change detection studies similar to the __[Decline of the world's saline lakes](https://www.nature.com/articles/ngeo3052)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "import geoviews as gv\n",
    "import datashader as ds\n",
    "import cartopy.crs as ccrs\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from holoviews.operation.datashader import regrid, shade\n",
    "from bokeh.tile_providers import STAMEN_TONER\n",
    "\n",
    "hv.extension('bokeh', width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Landsat Imae Data\n",
    "\n",
    "To replicate this study, we first have to obtain the data from primary sources.  The conventional way to obtain Landsat image data is to download it through USGS's \n",
    "__[EarthExpoyer](https://earthexplorer.usgs.gov/)__ or NASA's __[Giovanni](https://giovanni.gsfc.nasa.gov/giovanni/)__, but to facilitate the example two images have been downloaded from EarthExployer and cached.  \n",
    "\n",
    "The two images used by the original study are LT05_L1TP_042033_19881022_20161001_01_T1 and \n",
    "LC08_L1TP_042033_20171022_20171107_01_T1 from 1988/10/22 and 2017/10/22 respectivly.  These images contain Landsat Surface Reflectance Level-2 Science Product images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "lst_images = ['LT050420331988102201T1-SC20180424140822.tar.gz','LC080420332017102201T1-SC20180424140236.tar.gz']\n",
    "url = 'https://s3.amazonaws.com/datashader-data/'\n",
    "for fname in lst_images:\n",
    "    # only download and uncompress images if they are not already on your machine\n",
    "    if not os.path.exists(fname):\n",
    "        import urllib.request\n",
    "        print(\"downloading Landsat image file '%s'\"%fname)\n",
    "        urllib.request.urlretrieve(url+fname, fname)\n",
    "        \n",
    "        from subprocess import call\n",
    "        call([\"tar\", \"-xzvf\", fname]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrarily choose a small memory limit (4GB) to stress the \n",
    "# out of core processing infrastructure\n",
    "from dask.distributed import Client\n",
    "client = Client(memory_limit=4e9, processes=False) \n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANDSAT images 1988/10/22\n",
    "L5_files = sorted(glob.glob(\"LT05_L1TP_042033_19881022_20161001_01_T1_sr_band*.tif\"))\n",
    "print(\"number of Landsat-5 files =\",len(L5_files))\n",
    "#L5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANDSAT images 2017/10/22\n",
    "L8_files = sorted(glob.glob(\"LC08_L1TP_042033_20171022_20171107_01_T1_sr_band*.tif\"))\n",
    "print(\"number of Landsat-8 files =\",len(L8_files))\n",
    "#L8_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the images\n",
    "#L5_img = [xr.open_rasterio(f,chunks={'x':256,'y':256}) for f in L5_files]\n",
    "#print(\"attrs:\",L5_img.shape)\n",
    "#L5_img[1].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterio creates a 3D image (1,height,width).  We only need 2D\n",
    "L5_img = xr.concat([xr.open_rasterio(f,chunks={'band':1,'x':256,'y':256})[0,:,:] for f in L5_files])\n",
    "print(L5_img)\n",
    "print(\"attrs:\",L5_img.attrs)\n",
    "print(\"shape:\",L5_img.shape)\n",
    "print(\"chunks:\",L5_img.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_band(b):\n",
    "    nodata = b.attrs['nodatavals']\n",
    "    xs, ys = b['x'], b['y']\n",
    "    b = ds.utils.orient_array(b)\n",
    "    a = (np.where(np.logical_or(np.isnan(b),b<=nodata),0,255)).astype(np.uint8)    \n",
    "    col, rows = b.shape\n",
    "    return hv.RGB((xs, ys[::-1], b, b, b, a), vdims=list('RGBA'))\n",
    "\n",
    "# FIXME: need to reproject from WGS84 to UTM-11N, or transform data into WGS84\n",
    "%opts RGB [width=600 height=600]\n",
    "tiles = gv.WMTS(STAMEN_TONER)\n",
    "tiles * shade(regrid(one_band(L5_img[1].compute())), cmap=['black', 'white']).redim(x='Easting', y='Northing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
